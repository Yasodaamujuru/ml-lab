# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Step 1: Load dataset (Iris dataset for simplicity)
data = load_iris()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target)

# Step 2: Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 3: Initialize the Decision Tree Classifier (CART)
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# Step 4: Evaluate the model on test data
y_pred = dt_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", class_report)

# Plot the decision tree
plt.figure(figsize=(12,8))
plot_tree(dt_classifier, feature_names=data.feature_names, class_names=data.target_names, filled=True)
plt.show()
# Step 5: Apply Cost Complexity Pruning

# Get the effective alpha values for pruning
path = dt_classifier.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

# Train decision trees for each alpha value
classifiers = []
for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    classifiers.append(clf)

# Step 6: Evaluate and select the best pruned tree
train_scores = [clf.score(X_train, y_train) for clf in classifiers]
test_scores = [clf.score(X_test, y_test) for clf in classifiers]

# Plot accuracy vs. alpha
plt.figure(figsize=(8, 6))
plt.plot(ccp_alphas, train_scores, marker='o', label='Train Accuracy', drawstyle="steps-post")
plt.plot(ccp_alphas, test_scores, marker='o', label='Test Accuracy', drawstyle="steps-post")
plt.xlabel('Alpha')
plt.ylabel('Accuracy')
plt.title('Accuracy vs alpha for training and testing sets')
plt.legend()
plt.show()

# Step 7: Select the best alpha value (pruned tree)
best_alpha = ccp_alphas[np.argmax(test_scores)]
best_tree = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha)
best_tree.fit(X_train, y_train)

# Evaluate the pruned tree
y_pred_pruned = best_tree.predict(X_test)
pruned_accuracy = accuracy_score(y_test, y_pred_pruned)
pruned_conf_matrix = confusion_matrix(y_test, y_pred_pruned)
pruned_class_report = classification_report(y_test, y_pred_pruned)

print(f"Pruned Tree Accuracy: {pruned_accuracy:.2f}")
print("Pruned Tree Confusion Matrix:\n", pruned_conf_matrix)
print("Pruned Tree Classification Report:\n", pruned_class_report)

# Plot the pruned decision tree
plt.figure(figsize=(12,8))
plot_tree(best_tree, feature_names=data.feature_names, class_names=data.target_names, filled=True)
plt.show()

