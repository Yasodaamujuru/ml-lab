Lab 6 ML



1)# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.utils import to_categorical

# Load the dataset (assuming it's a CSV file)
# The dataset contains 7 features and 1 label column (variety of wheat)
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt"
columns = ["area", "perimeter", "compactness", "length_of_kernel", "width_of_kernel", "asymmetry_coefficient", "length_of_kernel_groove", "class"]

# Load the dataset into a pandas DataFrame
data = pd.read_csv(url, delim_whitespace=True, names=columns)

# Features (X) and labels (y)
X = data.drop("class", axis=1).values  # 7 features
y = data["class"].values  # Labels (class 1, 2, or 3)

# Convert the labels to one-hot encoding
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)  # Convert class labels to integers
y_one_hot = to_categorical(y_encoded)  # Convert integers to one-hot encoding

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)

# Scale the features (standardize them)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Import TensorFlow and Keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Construct the feedforward neural network
model = Sequential()

# Input layer and hidden layer (10 neurons with ReLU activation)
model.add(Dense(10, input_shape=(X_train_scaled.shape[1],), activation='relu'))

# Output layer (3 neurons, one for each class, with softmax activation)
model.add(Dense(3, activation='softmax'))

# Compile the model (using categorical crossentropy and SGD optimizer)
model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])

# Summarize the model structure
model.summary()
# Train the model using the training data
history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_split=0.2)
# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Make predictions
y_pred = model.predict(X_test_scaled)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels
y_true_classes = np.argmax(y_test, axis=1)

# Classification report
from sklearn.metrics import classification_report
print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_.astype(str)))
import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()
from tensorflow.keras.layers import Dropout

# Create the model with Dropout
model_with_dropout = Sequential()
model_with_dropout.add(Dense(10, input_shape=(X_train_scaled.shape[1],), activation='relu'))
model_with_dropout.add(Dropout(0.5))  # Dropout with 50% rate
model_with_dropout.add(Dense(3, activation='softmax'))

# Compile the model
model_with_dropout.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model with Dropout
history_dropout = model_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_split=0.2)

# Evaluate the model with Dropout
test_loss_dropout, test_accuracy_dropout = model_with_dropout.evaluate(X_test_scaled, y_test)
print(f"Test Accuracy with Dropout: {test_accuracy_dropout:.2f}")

